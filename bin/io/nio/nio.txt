1.虚拟内存
可以称为虚拟存储技术，而绝大部分操作系统使用的虚拟存储器技术就是分页技术，可以称主虚拟分页
虚拟分页就是虚拟内存在硬盘中以分页形式存在

虚拟内存就是系统匀出一部分硬盘空间来充当内存使用.当内存耗尽时，电脑就会自动调用硬盘来充当内存，以缓解内存的紧张.
若计算机运行程序或 操作所需的 随机存储器(RAM，可以理解为物理内存)不足时，则 Windows 会用虚拟存储器进行补偿.
它将计算机的RAM和硬盘上的临时空间组合,当RAM运行速率缓慢时，它便将数据从RAM移动到称为“虚拟分页文件”的空间中.
将数据移入分页文件可释放RAM，以便完成工作.
 一般而言，计算机的RAM容量越大，程序运行得越快.若计算机的速率由于RAM可用空间匮乏而减缓，则可尝试通过增加虚拟内存来进行补偿.
 但是，计算机从RAM读取数据的速率要比从硬盘读取数据的速率快，因而扩增RAM容量（可加内存条）是最佳选择

在虚拟存储器中(或称为虚拟内存中)，程序所产生的地址为虚拟地址，虚拟地址构成了虚拟地址空间,虚拟地址通过MMU（内存管理单元）映射为物理地址

采用分页机制的系统，虚拟地址空间以页面为单位进行划分，虚拟地址空间会被划分成多个等大小的页面.
物理地址空间也按页面为单位进行划分每一块成为页帧，或者页框.
每一虚拟页面可以随意对应到物理页框，也可以对应到磁盘的页面文件上

我们按照IA32的分页机制来说，标准页面大小为4K。 
         例如一条mov指令： mov   eax,	[0]; 
         此时虚拟地址0将被发给MMU，MMU发现虚拟地址0属于虚拟页面0的范围内，
         如果虚拟页面0对应的物理地址空间页框号为1，那么物理地址在物理地址4096-8191范围，此时就会将4096发送到地址总线上
         
	因为页面大小为4k,所以按如下分布
	0--->[0-4095]
	1--->[4096, 8191]
	
	因为虚拟地址0的页内偏移也是0（页内偏移：在页面里的位置，这是因为一个页面大小为4K，用虚拟地址   mod 4k(虚拟地址/4096)就得到了页内偏移）
         就类似mov eax,[4095];
         mov eax,[4096],
         4095 mod 4096为0, 属于页面0，如果页面0对应页框1，那么物理地址为8191，因为4095在物理地址空间页面0中是最后一个元素，对应虚拟空间第1页的最后一个元素就是8191
		  而虚拟地址4096属于页面1的范围，如果页面1对应页框0，此时的物理地址就是0，因为4096在物理地址空间页面1中是第一个元素，对应虚拟空间第0页的第一个元素就是0
		
        由上面可以看出，虚拟地址空间是连续的，而物理空间是可以不连续的。也就是说一个程序只要保证他的虚拟地址空间是连续的，它就可以正常运行
        
虚拟内存的实现方法-------摘自《加密与解密》
1).当一个应用程序被启动时，操作系统就创建一个新进程，并给每个进程分配2gb的内存地址（不是内存只是地址）
2).虚拟内存管理器将应用程序的代码映射到那个程序的虚拟地址中得某个位置，并把当前所需的代码读取到物理地址中
	可以理解为虚拟地址中有一个应用程序的地址与物理地址对应，该物理地址存放着实际的代码
	
	
3).如果使用动态链接库DLL，DLL也被映射到进程的虚拟地址空间，在需要的时候才被读入物理地址
4).其他项目（如数据，堆栈）的空间是从物理地址中分配的，并被映射到虚拟地址空间中
5).应用程序通过使用它的虚拟地址空间中的地址开始执行，然后虚拟内存管理器把每次的内存访问映射到物理位置
	程序由CPU调度执行，CPU会引用应用程序所在的虚拟地址开始执行，MMU负责确定该虚拟内存地址所在页，
	并将虚拟页号转换为物理页号，如果当前物理内存不存在与该虚拟页形成有效映射的物理内存页，MMU会向CPU
	提交一个页错误，页错误随即产生一个陷阱（类似于系统调用）， 把控制权移交给内核，附带导致页错误的虚拟地址信息，
	然后内核采取步骤验证页（这个页应该是物理页）的有效性，内核会安排页面调入操作，把缺失的页内容读回物理内存，
	这往往会导致别的物理页被移出物理内存，好给新来的页让地方，在这种情况下，如果待移动的物理页已经被碰过了（内容发生了改变），
	还必须首先执行页面调出，把页内容拷贝到磁盘上的分布区。
	如果 所要要求的地址不是有效的虚拟内存地址（不属于正在执行的进程的任何一个内存段），则该页不能通过验证
	一旦出错的页通过了验证，ＭＭＵ随即更新，建立新的虚拟到物理的映射，用户进程得以继续

2.套接字
源IP地址和目的IP地址以及源端口号和目的端口号的组合称为套接字

3. java io原理,附图
 ---------------------------------------------------------
|		User space		|		Kernel space			  |	
|	-----------------	|								  |
    |   ---------   |左箭头				DMA		    ------------  向左箭头,Hardware
|	|	| buffer|--	|---|-----------	-----------	| Disk		|-------
    |   ---------   |	|			|	|向下箭头		|controller	|		|
|	|				|	|		-------------		-------------	--------
|	|	Process 	|	|		|	buffer	|			  | 		| Disk	|
|	|				|	|		-------------			  |	     	---------
|	-----------------	|								  |
|						|								  |
----------------------------------------------------------|

在传统的文件IO操作中，此处以java IO为例，都是调用操作系统提供的底层标准IO系统调用函数read(),write()
以FileInputStream.read()方法为例，
public native int read() throws IOException
他会调用native的read方法，即调用c代码中的read方法，
java进程会发起请求，要求其用户空间的缓冲通过调用系统提供的read()方法 将其填满，这个系统调用导致内核向磁盘
控制器发出一条指令，要求从磁盘获取数据，磁盘控制器通过DMA直接将数据写入到内核的内存缓冲区，完成后，内核用户
空间从内核的缓存区拷贝数据到进程指定的缓存中
为什么不把数据直接拷贝到进程指定的缓存中，要先拷贝到内核缓存中呢？
这么做是为了减少ＩＯ操作，为了提高性能而考虑的，因为我们的程序访问一般都带有局部性，在这里主要指的是空间局部性，
即我们访问了文件的某一段数据，那么接下去很可能还会访问接下去的一段数据，由于磁盘ＩＯ操作的速度比直接访问内存
慢了好几个数量级，所以ＯＳ根据局部性原理会在一次read()系统调用过程中预读更多的文件数据缓存在内核缓冲区中，当
继续访问的文件数据在缓冲区中时，便直接拷贝数据到java进程指定的缓冲区中，避免了低效的磁盘ＩＯ操作

比如我们要读10个字节，调用read()方法，要系统调用10次，没有内核缓冲区的吧，还要10次磁盘IO操作，有了内核缓冲区，
只需要一次IO操作，系统调用也是耗时的操作(用户态和内核态的切换 等 操作)，所以java提供了BufferedInputStream,
这里的缓冲是为了减少系统调用，不是磁盘IO,BufferedInputStream会根据情况自动为我们预读更多的字节数据到他自己维护的一个
内部字节数组缓冲区中，这样可以减少系统调用


磁盘
磁盘的块大小(Block Size)和扇区大小(Sector Size)
块大小一般为扇区大小的数倍

要明确的是，块是文件系统的抽象，不是磁盘本身的属性。
扇区大小则是磁盘的物理属性，它是磁盘设备寻址的最小单元

通过fdsik -l 可以查看linux系统下的磁盘信息，类似如下
Disk /dev/hda: 80.0 GB, 80026361856 bytes
255 heads, 63 sectors/track, 9729 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes

磁头数(Heads)表示硬盘总共有几个磁头,也就是有几面盘片, 最大为 255 (用 8 个二进制位存储);
柱面数(Cylinders) 表示硬盘每一面盘片上有几条磁道,最大为 1023(用 10 个二进制位存储);
扇区数(Sectors) 表示每一条磁道上有几个扇区, 最大为 63(用 6个二进制位存储).
每个扇区一般是 512个字节, 理论上讲这不是必须的,但好象没有取别的值的.
通过上面的例子，我们发现此硬盘有 255个磁盘面，有63个扇区，有9729个柱面；所以整个硬盘体积换算公式应该是：

磁面个数 x 扇区个数 x 每个扇区的大小512 x 柱面个数 = 硬盘体积 （单位bytes)
所以在本例中磁盘的大小应该计算如下：
255 x 63 x 512 x 9729 = 80023749120 bytes

同步和异步
同步和异步着重点在于多个任务的执行过程中，一个任务的执行是否会导致整个流程的暂时等待

阻塞和非阻塞
而阻塞和非阻塞着重点在于发出一个请求操作时，如果进行操作的条件不满足是否会返会一个标志信息告知条件不满足
举个简单的例子：
假如我要读取一个文件中的内容，如果此时文件中没有内容可读，对于同步来说就是会一直在那等待，直至文件中有内容可读；而对于非阻塞来说，
就会直接返回一个标志信息告知文件中暂时无内容可读

阻塞IO和非阻塞IO
通常来说，IO操作包括：对硬盘的读写、对socket的读写以及外设的读写。
　　当用户线程发起一个IO请求操作（本文以读请求操作为例），内核会去查看要读取的数据是否就绪，对于阻塞IO来说，如果数据没有就绪，
则会一直在那等待，直到数据就绪；对于非阻塞IO来说，如果数据没有就绪，则会返回一个标志信息告知用户线程当前要读的数据没有就绪。
当数据就绪之后，便将数据拷贝到用户线程，这样才完成了一个完整的IO读请求操作，也就是说一个完整的IO读请求操作包括两个阶段：
　　1）查看数据是否就绪；
　　2）进行数据拷贝（内核将数据拷贝到用户线程）。
　　那么阻塞（blocking IO）和非阻塞（non-blocking IO）的区别就在于第一个阶段，如果数据没有就绪，在查看数据是否就绪的过程中是一直等待，
还是直接返回一个标志信息。
　　Java中传统的IO都是阻塞IO，比如通过socket来读数据，调用read()方法之后，如果数据没有就绪，当前线程就会一直阻塞在read方法调用那里，
直到有数据才返回；而如果是非阻塞IO的话，当数据没有就绪，read()方法应该返回一个标志信息，告知当前线程数据没有就绪，
而不是一直在那里等待

在非阻塞IO模型中，用户线程需要不断地询问内核数据是否就绪，也就说非阻塞IO不会交出CPU，而会一直占用CPU
典型的非阻塞IO模型一般如下：
while(true){
    data = socket.read();
    if(data!= error){
        处理数据
        break;
    }
}

典型的阻塞IO模型的例子为
data = socket.read()
如果数据没有就绪，就会一直阻塞在read方法

同步IO和异步IO
我们先来看一下同步IO和异步IO的定义，在《Unix网络编程》一书中对同步IO和异步IO的定义是这样的：

A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes.
An asynchronous I/O operation does not cause the requesting process to be blocked.

从字面的意思可以看出：同步IO即 如果一个线程请求进行IO操作，在IO操作完成之前，该线程会被阻塞；
而异步IO为 如果一个线程请求进行IO操作，IO操作不会导致请求线程被阻塞。

事实上，同步IO和异步IO模型是针对用户线程和内核的交互来说的：
对于同步IO：当用户发出IO请求操作之后，如果数据没有就绪，需要通过用户线程或者内核不断地去轮询数据是否就绪，当数据就绪时，
再将数据从内核拷贝到用户线程；

而异步IO：只有IO请求操作的发出是由用户线程来进行的，
IO操作的两个阶段都是由内核自动完成，然后发送通知告知用户线程IO操作已经完成。也就是说在异步IO中，不会对用户线程产生任何阻塞。

这是同步IO和异步IO关键区别所在，同步IO和异步IO的关键区别反映在数据拷贝阶段是由用户线程完成还是内核完成.
所以说异步IO必须要有操作系统的底层支持。

注意同步IO和异步IO与阻塞IO和非阻塞IO是不同的两组概念。
阻塞IO和非阻塞IO是反映在当用户请求IO操作时，如果数据没有就绪，是用户线程一直等待数据就绪，还是会收到一个标志信息这一点上面的。
也就是说，阻塞IO和非阻塞IO是反映在IO操作的第一个阶段，在查看数据是否就绪时是如何处理的。

多路复用IO模型
　　多路复用IO模型是目前使用得比较多的模型。Java NIO实际上就是多路复用IO。
　　在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。
因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，
并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。
　　在Java NIO中，是通过selector.select()去查询每个通道是否有到达事件，如果没有事件，则一直阻塞在那里，
因此这种方式会导致用户线程的阻塞。
　　也许有朋友会说，我可以采用 多线程+ 阻塞IO 达到类似的效果，但是由于在多线程 + 阻塞IO 中，每个socket对应一个线程，
这样会造成很大的资源占用，并且尤其是对于长连接来说，线程的资源一直不会释放，如果后面陆续有很多连接的话，就会造成性能上的瓶颈。

　　而多路复用IO模式，通过一个线程就可以管理多个socket，只有当socket真正有读写事件发生才会占用资源来进行实际的读写操作。因此，
多路复用IO比较适合连接数比较多的情况。
　　另外多路复用IO为何比非阻塞IO模型的效率高是因为在非阻塞IO中，不断地询问socket状态时通过用户线程去进行的，
而在多路复用IO中，轮询每个socket状态是内核在进行的，这个效率要比用户线程要高的多。

　　不过要注意的是，多路复用IO模型是通过轮询的方式来检测是否有事件到达，并且对到达的事件逐一进行响应。
因此对于多路复用IO模型来说，一旦事件响应体很大，那么就会导致后续的事件迟迟得不到处理，并且会影响新的事件轮询

异步IO模型
　　异步IO模型才是最理想的IO模型，在异步IO模型中，当用户线程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，
从内核的角度，当它受到一个asynchronous read之后，它会立刻返回，说明read请求已经成功发起了，因此不会对用户线程产生任何block。
然后，内核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程发送一个信号，告诉它read操作完成了。
也就说用户线程完全不需要知道实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，
可以直接去使用数据了。
　　也就说在异步IO模型中，IO操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完成，然后发送一个信号告知用户线程操作已完成。
用户线程中不需要再次调用IO函数进行具体的读写。这点是和信号驱动模型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据已经就绪
，然后需要用户线程调用IO函数进行实际的读写操作；而在异步IO模型中，收到信号表示IO操作已经完成，不需要再在用户线程中调用iO函数进行实
际的读写操作。
　　注意，异步IO是需要操作系统的底层支持，在Java 7中，提供了Asynchronous IO。
　　前面四种IO模型实际上都属于同步IO，只有最后一种是真正的异步IO，因为无论是多路复用IO还是信号驱动模型，
IO操作的第2个阶段都会引起用户线程阻塞，也就是内核进行数据拷贝的过程都会让用户线程阻塞。
