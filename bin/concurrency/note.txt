----------------------未捕获异常处理器---------------------------
当线程抛出一个未捕获到的异常时，JVM将为异常寻找以下三种可能的处理器
1.首先查找线程对象的未捕获线程处理器
2.若1不存在，JVM继续查找线程对象所在的线程组的未捕获异常处理器
3.若2也不存在，JVM将继续查找默认的未捕获异常处理器
4.若线程没有被预置未捕获异常处理器，JVM将打印堆栈记录到控制台，并退出程序
----------------------未捕获异常处理器---------------------------

----------------------锁---------------------------
Lock接口，实现类ReentrantLock
ReadWiterLock接口，实现类ReentrantReadWriteLock
ReentrantReadWriteLock有两个锁，一个读锁，一个写锁，使用读操作锁时可以
允许多个线程同时访问，但是使用写操作锁时只允许一个线程进行
在写操作锁的时候，可以进入读锁操作

Lock.newCondition.await对应Object.wait(await有延时方法，await方法要用在while循环中)
Lock.newCondition.signal or signalAll对应Object.notify or notifyAll
可以参考源代码LinkedBlockingQueue,他实现了类似生产者消费者模式
----------------------锁---------------------------

----------------------同步辅助类---------------------------
Semaphore(资源的单副本或多副本的并发访问控制)
是一种计数器，用来保护一个或者多个共享资源的访问,在应用程序中，任何时候都可以用Semaphore来保护临界区，因为它是一个基础同步
机制，而其他的同步机制则需要根据各自的特性来选择使用
Semaphore.acquire,减少一个允许
Semaphore.release，增加一个允许
控制访问某种共享资源的线程数，比如说一个打印机同时只能由一个人使用，另外一个人必须在别人用完后才能打印，这只可以设置允许的
数量为1

CountDownLatch（等待多个并发事件的完成）
在完成一组正在其他线程中执行的操作之前，它允许线程一直等待
调用await的线程，必须等待其他所有线程都完成了，才能继续往下执行
CountDownLatch.await
CountDownLatch.countDown
一般是一个线程调用await方法，然后其他线程调用countDown方法，共享一个CountDownLatch对象

CyclicBarrier(在集合点的同步)
允许两个或多个线程在某个点上进行同步
使用整数进行初始化，这个数是需要在某个点上同步的线程数
当所有的线程都到达集中点后，可以开启一个新线程进行统一操作(比如汇总统计什么的)，可以将runnable作为初始化参数，以开启一个新的线程 
CyclicBarrier的reset()具有重置功能，让CyclicBarrier恢复到初始状态，可以继续使用,但CountDownLatch一旦倒计数到0后就结束了，不
能重复使用

Phaser(并发多阶段任务的运行)
当我们有并发任务且需要分解成几步执行时，这种机制就非常适应，Phaser类机制是在每一步结束的位置对线程进行同步，
即会等待所有线程都完成这一步然后才执行下一步

Exchanger(并发任务间的数据交换)
当两个线程都到达同步点时，它们交换数据结构，因此第一个线程的数据结构进入到第二个线程中，同时第二个线程的数据结构进入到第一个线程中
Exchanger类在生产者-消费者问题情境中很有用，这是一个经典的并发场景，包含一个数据缓冲区，一个或者多个数据生产者，一个或者多个消费者，
Exchanger只能同步两个线程，如果有类似的只有一个生产者和消费者的问题，就可以用Exchanger类
----------------------同步辅助类---------------------------

----------------------并发执行器---------------------------
接口Executor
void execute(Runnable command);
很多方法
shutdown() 对以前提交的任务开始有序的关闭，不再接受新的任务，也不一定会等待以前提交的任务执行完成再关闭
shutdownNow() 尝试关闭当前正在执行的任务，停止对等待任务的处理，返回等待处理的任务列表
isShutdown()
isTerminated() 返回true，如果所有的任务都被执行完成，这个判断必须基于shutdown()和shutdownNow()方法被调用，否则返回false
awaitTermination(...,...) 调用shutdown()后，再调用该方法，等待任务执行完成
<T> Future<T> submit(Callable<T> task)
<T> Future<T> submit(Runnable task, T result)
Future<?> submit(Runnable task)
<T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)
        throws InterruptedException
<T> T invokeAny(Collection<? extends Callable<T>> tasks)
        throws InterruptedException, ExecutionException

接口ExecutorService extends Executor
抽象类AbstractExecutorService implements ExecutorService
类ThreadPoolExecutor extends AbstractExecutorService

Executors工厂类，创建不同的线程池执行器,下面分别介绍

一个线程池，创建新的线程如果需要的话，初始化线程数目为0,当有新的task进来时，会创建新的线程，
如果池中有空闲的线程的话，可以重用
缓存池比较适合这种场合: 异步的task, task多，但task执行时间短
超过60s空闲，线程会被remove, 所以在长时间来看，这个级存池会比较空闲，不会占用太多资源
当发送大量的任务给这个执行器并且任务需要较长的时间，系统将会超负荷，因为任务执行时间较长，
意味着不能重用，不能重用每次就可能都要创建新的线程，这样性能就不佳了
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>());
}


线程池的初始值大小和最大线程数目是一样的，超时是0秒，意味着不会超时，使用的队列是有选择的有界队列，FIFO
当新的task进来，发现没有空闲的线程，这些task会在队列中等待，如果线程因为某咱原因挂了，会有新的线程
来代替，池中的线程会一直存在，直到调用shutdown方法 
public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue<Runnable>());
}


相当于是newFixedThreadPool(1)
public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>()));
}


定时的线程池或周期性，corePoolSize，池中保持的线程数，即使是空闲的
public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
    return new ScheduledThreadPoolExecutor(corePoolSize);
}

public ScheduledThreadPoolExecutor(int corePoolSize) {
    super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS,
          new DelayedWorkQueue());
}

Runnable
public abstract void run()

在执行器中执行任务并返回结果
Callable
V call() throws Exception

Future
boolean isDone();
V get()

RunnableFuture<V> extends Runnable, Future<V>
FutureTask<V> implements RunnableFuture<V>
void run()

运行多个任务只处理第一个结果
invokeAny()
执行一系列的task,只要有一个成功返回(没有异常)，就结束，有异常抛出认为不成功


运行多个任务处理所有结果
invokeAll()
invokeAll相当于是批量处理，跟多次执行单个submit差别不大

如果想要等待任务结束，使用如下两种方法
* Future.isDone(), 如果任务执行结束，返回true
* 调用shutdown()后，ThreadPoolExecutor.awaitTermination()会将线程休眠，直到所有的任务执行结束
上面两种方法都不是很好,第三种invokeAll()

在执行器中取消任务
Future.cancel()

在执行器中控制任务的完成
override FutureTask's done()

在执行器中分离任务的启动与结果的处理
CompletionService
感觉这个跟普通的通过Future.get不有太大差别

处理在执行器中被拒绝的任务（实现接口RejectedExecutionHandler）
如果在shutdown()方法与执行器结束之间发送一个任务给执行器，这个任务会被拒绝，因为这个时间段执行器已经不
再接受新的任务了
ThreadPoolExecutor类提供了一套机制，当任务被拒绝时，调用这套机制来处理它们
通过设置ThreadPoolExecutor.setRejectedExecutionHandler(new RejectedExecutionHandler(){})

----------------------并发执行器---------------------------


----------------------Fork/Join---------------------------
ForkJoinPool类看作一个特殊的Executor执行器类型
这个框架基于以下两种操作
分解操作(Fork)
合并操作(Join)

Fork/Join框架和执行器框架主要的区别在于工作窃算法，与执行器框架不同，使用join操作让一个主任务等待它所创建的子任务的完成，
执行这个子任务的线程称之为工作者线程，工作者线程寻找其他仍未被执行的子任务，然后执行，这些工作者线程在运行时拥有所有的优点，
进而提升性能

为了达到这个目标，该框架有以下限制
	*任务只能使用Fork/Join操作当作同步机制，如果使用其他的同步机制，工作者线程就不能执行其他任务。比如在Fork/Join框架中将
	一个任务休眠，正在执行这个任务的工作者线程在休眠期内不能执行另一个线程
	*任务不能执行IO操作
	*任务不能抛出非运行时异常
	
该框架由下列两个类组成
	*ForkJoinPool:实现了ExecutorService接口和工作窃取算法，管理工作者线程
class ForkJoinPool extends AbstractExecutorService

	*ForkJoinTask:这个类是一个将在ForkJoinPool中执行的任务的基类
abstract class ForkJoinTask<V> implements Future<V>, Serializable
RecursiveAction extends ForkJoinTask
RecursiveTask extends ForkJoinTask

为了实现Fork/Join任务，需要实现下面两个类中的其中一个
	*RecursiveAction:用于任务没有返回结果的场景
	*RecursiveTask:用于任务有返回结果的场景
	
工作窃取算法
工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行
那么为什么需要使用工作窃取算法呢？假如我们需要做一个比较大的任务，我们可以把这个任务分割为若干互不依赖的子任务，
为了减少线程间的竞争，于是把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，
线程和队列一一对应，比如A线程负责处理A队列里的任务。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务
等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。
而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，
被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程(已经完成了自己任务的线程)永远从双端队列的尾部拿任务执行。

      							------------------------------------
 队列进,该队列对应线程从头部取线程	|    |    |    |    |    |    |    | 队列出，其他队列线程，窃取线程，从尾部取任务
      							------------------------------------

工作窃取算法的优点是充分利用线程进行并行计算，并减少了线程间的竞争，其缺点是在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且消耗了更多的系统资源，比如创建多个线程和多个双端队列。

ForkJoinPool创建对象时，即new时，会初始化并行任务的线程数目，默认是机器的核数，四核就是四个,但会随着子任务的增加而增加;
调用ForkJoinPool.execute(...)方法，如果是ForkJoinTask任务，调用forkOrSubmit(job);
入队列，创建或者唤醒工作者线程ForkJoinWorkerThread，启动线程执行任务	

Fork/Join的工作过程，一开始只有一个大任务，通过ForkJoinPool.execute()执行，然后会创建第一个工作者线程执行这个大任务，
任务太大，不满足，开始分割，产生多个子任务，入队列到当前线程对应的队列中，用A队列表示，这时其他空闲的线程（默认认为寝化了四个工作者线程）
会窃取A队列中的任务进行执行，若执行过程中发现该窃取来的任务不足够小的话，也会继续拆分，直到拆分成可以执行为止，其他空闲的工作者线程
类似这样操作，每一个子任务都会产生一个结果（如果有返回结果的话），最后会对所有的结果进行合并

----------------------Fork/Join---------------------------

----------------------并发集合---------------------------
阻塞式集合
LinkedBlockingDeque(阻塞式列表)
LinkedTransferQueue(用于数据生成或消费的阻塞式列表)
PriorityBlockingQueue(按优先级排序)
队列中的元素必须实现Comparable接口，这样可以比较，优先级最高的是第一个元素

DelayQueue（带有延迟列表元素）
队列中的元素必须实现Delay接口

非阻塞式集合
ConcurrentLinkedDeque（非阻塞式列表）
ConcurrentSkipListMap(非阻塞式可遍历映射)
ThreadLocalRandon(随机数字对应的实现类)
AtomicLong和AtomicIntegerArray（原子变量对应的实现类）

----------------------并发集合---------------------------

---------------------并行与并发概念-----------------------
并行是指两个或者多个事件在同一时刻发生
而并发是指两个或多个事件在同一时间间隔内发生

并发与并行是两个既相似而又不相同的概念，并发是指能处理多个同时性活动的能力，并行是指
同时发生的两个并发事件，具有并发的含义，而并发则不一定是并行，并发事件不一定要同一时刻发生
并发的实质是一个物理CPU（也可以多个物理CPU）在若干程序之间多路复用
并行性是指两个或两个以上事件或活动在同一时刻发生
并发是同一个CPU上同时运行多个程序
并行是每个CPU运行一个程序
---------------------并行与并发概念-----------------------